from __future__ import annotations
import json
import logging
from pathlib import Path
from typing import List, Tuple, Dict, Any
import numpy as np
from PIL import Image
import cv2
from ..config import CONFIG

try:
    import onnxruntime as ort
except ImportError:
    ort = None

class DetectionResult:
    """ê°ì§€ ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” í´ë˜ìŠ¤"""
    def __init__(self, bbox: Tuple[float, float, float, float], confidence: float, class_id: int = 0):
        self.bbox = bbox  # (x1, y1, x2, y2) in original image coordinates
        self.confidence = confidence
        self.class_id = class_id
        self.class_name = "mitosis"

    def __repr__(self):
        return f"DetectionResult(bbox={self.bbox}, conf={self.confidence:.3f})"

class MitosisDetector:
    """YOLOv12 ONNX ëª¨ë¸ì„ ì‚¬ìš©í•œ Mitosis ê°ì§€ê¸°"""

    def __init__(self, model_path: str = None, config_path: str = None):
        self.logger = logging.getLogger(__name__)

        # configì—ì„œ ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
        if model_path is None:
            model_path = CONFIG.ai.model_path
        if config_path is None:
            config_path = CONFIG.ai.config_path

        self.model_path = Path(model_path)
        self.config_path = Path(config_path)

        # ì„¤ì • ë¡œë“œ
        self.config = self._load_config()
        self.session = None
        self.input_name = None
        self.output_names = None

        # ëª¨ë¸ ì´ˆê¸°í™”
        self._initialize_model()

    def _load_config(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            if self.config_path.exists():
                with open(self.config_path, 'r') as f:
                    config = json.load(f)
                return config.get("mitosis_yolov12", {})
            else:
                self.logger.warning(f"Config file not found: {self.config_path}")
                # ê¸°ë³¸ ì„¤ì • ë°˜í™˜
                return {
                    "input_size": [640, 640],
                    "confidence_threshold": 0.5,
                    "nms_threshold": 0.4,
                    "class_names": ["mitosis"],
                    "preprocessing": {
                        "normalize": True,
                        "mean": [0.485, 0.456, 0.406],
                        "std": [0.229, 0.224, 0.225]
                    }
                }
        except Exception as e:
            self.logger.error(f"Error loading config: {e}")
            return {}

    def _initialize_model(self):
        """ONNX ëª¨ë¸ ì´ˆê¸°í™”"""
        if ort is None:
            raise RuntimeError(
                "onnxruntimeê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                "ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install onnxruntime-gpu"
            )

        if not self.model_path.exists():
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")

        try:
            # ONNX Runtime ì„¸ì…˜ ìƒì„±
            providers = self._get_providers()
            self.logger.info(f"Using providers: {providers}")

            self.session = ort.InferenceSession(
                str(self.model_path),
                providers=providers
            )

            # ì‹¤ì œ ì‚¬ìš© ì¤‘ì¸ provider í™•ì¸
            actual_providers = self.session.get_providers()
            self.logger.info(f"=== GPU ì‹¤í–‰ í™•ì¸ ===")
            self.logger.info(f"ìš”ì²­í•œ providers: {providers}")
            self.logger.info(f"ì‹¤ì œ ì‚¬ìš© ì¤‘ì¸ providers: {actual_providers}")

            if 'TensorrtExecutionProvider' in actual_providers:
                print("ğŸš€ TensorRTë¡œ ì‹¤í–‰ ì¤‘!")
                self.logger.info("ğŸš€ TensorRTë¡œ ì‹¤í–‰ ì¤‘!")
            elif 'CUDAExecutionProvider' in actual_providers:
                error_msg = "âŒ CUDAë¡œ ì‹¤í–‰ë˜ê³  ìˆìŠµë‹ˆë‹¤! TensorRTë§Œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤."
                print(error_msg)
                self.logger.error(error_msg)
                raise RuntimeError(error_msg)
            else:
                error_msg = "âŒ CPUë¡œ ì‹¤í–‰ë˜ê³  ìˆìŠµë‹ˆë‹¤! TensorRTë§Œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤."
                print(error_msg)
                self.logger.error(error_msg)
                raise RuntimeError(error_msg)

            # ì…ë ¥/ì¶œë ¥ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            self.input_name = self.session.get_inputs()[0].name
            self.output_names = [output.name for output in self.session.get_outputs()]

            input_shape = self.session.get_inputs()[0].shape
            self.logger.info(f"Model initialized. Input shape: {input_shape}")
            self.logger.info(f"Input name: {self.input_name}")
            self.logger.info(f"Output names: {self.output_names}")

        except Exception as e:
            self.logger.error(f"Failed to initialize ONNX model: {e}")
            raise

    def _get_providers(self) -> List[str]:
        """TensorRTë§Œ ì‚¬ìš©í•˜ëŠ” ì œê³µì ë°˜í™˜"""
        providers = []

        # TensorRTë§Œ ì‚¬ìš©
        available_providers = ort.get_available_providers()
        if "TensorrtExecutionProvider" in available_providers:
            providers.append("TensorrtExecutionProvider")
            self.logger.info("TensorRT provider available")
        else:
            raise RuntimeError(
                "TensorRTê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. "
                "TensorRT ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì„¤ì¹˜í•˜ê³  PATHì— ì¶”ê°€í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
            )

        # CUDAë‚˜ CPUëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ - TensorRT ì „ìš©
        self.logger.info(f"Final providers: {providers}")
        return providers

    def preprocess_image(self, image: np.ndarray) -> np.ndarray:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        # configì—ì„œ ëª¨ë¸ ì…ë ¥ í¬ê¸° ê°€ì ¸ì˜¤ê¸°, ì—†ìœ¼ë©´ ì„¤ì •ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        from ..config import CONFIG
        model_input_size = CONFIG.ai.model_input_size
        input_size = self.config.get("input_size", [model_input_size, model_input_size])
        preprocess_config = self.config.get("preprocessing", {})

        # í¬ê¸° ì¡°ì •
        h, w = image.shape[:2]
        target_h, target_w = input_size

        # ì¢…íš¡ë¹„ ìœ ì§€í•˜ë©° ë¦¬ì‚¬ì´ì¦ˆ
        scale = min(target_w / w, target_h / h)
        new_w, new_h = int(w * scale), int(h * scale)

        # ë¦¬ì‚¬ì´ì¦ˆ
        resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)

        # íŒ¨ë”© ì¶”ê°€ (íšŒìƒ‰ìœ¼ë¡œ)
        padded = np.full((target_h, target_w, 3), 114, dtype=np.uint8)
        pad_x = (target_w - new_w) // 2
        pad_y = (target_h - new_h) // 2
        padded[pad_y:pad_y+new_h, pad_x:pad_x+new_w] = resized

        # RGBë¡œ ë³€í™˜ ë° ì •ê·œí™”
        processed = padded.astype(np.float32) / 255.0

        if preprocess_config.get("normalize", False):
            mean = np.array(preprocess_config.get("mean", [0.485, 0.456, 0.406]), dtype=np.float32)
            std = np.array(preprocess_config.get("std", [0.229, 0.224, 0.225]), dtype=np.float32)
            processed = (processed - mean) / std

        # CHW í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ë° ë°°ì¹˜ ì°¨ì› ì¶”ê°€
        processed = processed.transpose(2, 0, 1)
        processed = np.expand_dims(processed, axis=0)

        # ë°ì´í„° íƒ€ì…ì„ float32ë¡œ í™•ì‹¤íˆ ë³´ì¥
        processed = processed.astype(np.float32)

        return processed, scale, (pad_x, pad_y)

    def postprocess_outputs(self, outputs: List[np.ndarray], scale: float,
                          pad_offset: Tuple[int, int], original_size: Tuple[int, int]) -> List[DetectionResult]:
        """ëª¨ë¸ ì¶œë ¥ í›„ì²˜ë¦¬"""
        if not outputs or len(outputs) == 0:
            return []

        predictions = outputs[0]  # Shape: (1, num_detections, 85) for YOLOv12

        if len(predictions.shape) == 3:
            predictions = predictions[0]  # Remove batch dimension

        confidence_threshold = self.config.get("confidence_threshold", 0.5)
        nms_threshold = self.config.get("nms_threshold", 0.4)

        # ì‹ ë¢°ë„ í•„í„°ë§
        confidences = predictions[:, 4]
        valid_indices = confidences > confidence_threshold
        valid_predictions = predictions[valid_indices]

        if len(valid_predictions) == 0:
            return []

        # ë°”ìš´ë”© ë°•ìŠ¤ ë³€í™˜
        boxes = valid_predictions[:, :4]  # (center_x, center_y, width, height)
        confidences = valid_predictions[:, 4]

        # ì¤‘ì‹¬ì¢Œí‘œ + í¬ê¸° â†’ ëª¨ì„œë¦¬ ì¢Œí‘œ
        x1 = boxes[:, 0] - boxes[:, 2] / 2
        y1 = boxes[:, 1] - boxes[:, 3] / 2
        x2 = boxes[:, 0] + boxes[:, 2] / 2
        y2 = boxes[:, 1] + boxes[:, 3] / 2

        boxes = np.column_stack([x1, y1, x2, y2])

        # NMS ì ìš©
        indices = cv2.dnn.NMSBoxes(
            boxes.tolist(),
            confidences.tolist(),
            confidence_threshold,
            nms_threshold
        )

        results = []
        if len(indices) > 0:
            if isinstance(indices, np.ndarray):
                indices = indices.flatten()

            pad_x, pad_y = pad_offset
            original_w, original_h = original_size

            for i in indices:
                box = boxes[i]
                conf = confidences[i]

                # ì¢Œí‘œë¥¼ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë³€í™˜
                x1 = (box[0] - pad_x) / scale
                y1 = (box[1] - pad_y) / scale
                x2 = (box[2] - pad_x) / scale
                y2 = (box[3] - pad_y) / scale

                # ì¢Œí‘œ ë²”ìœ„ ì œí•œ
                x1 = max(0, min(x1, original_w))
                y1 = max(0, min(y1, original_h))
                x2 = max(0, min(x2, original_w))
                y2 = max(0, min(y2, original_h))

                results.append(DetectionResult((x1, y1, x2, y2), conf))

        return results

    def detect(self, image: np.ndarray) -> List[DetectionResult]:
        """ì´ë¯¸ì§€ì—ì„œ mitosis ê°ì§€"""
        if self.session is None:
            raise RuntimeError("ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        original_size = (image.shape[1], image.shape[0])  # (width, height)

        try:
            # ì „ì²˜ë¦¬
            processed_image, scale, pad_offset = self.preprocess_image(image)

            # ì¶”ë¡ 
            outputs = self.session.run(
                self.output_names,
                {self.input_name: processed_image}
            )

            # í›„ì²˜ë¦¬
            results = self.postprocess_outputs(outputs, scale, pad_offset, original_size)

            self.logger.info(f"Detected {len(results)} mitosis candidates")
            return results

        except Exception as e:
            self.logger.error(f"Detection failed: {e}")
            raise

    def detect_from_pil(self, pil_image: Image.Image) -> List[DetectionResult]:
        """PIL ì´ë¯¸ì§€ì—ì„œ mitosis ê°ì§€"""
        # PIL â†’ OpenCV í˜•ì‹ ë³€í™˜
        image_array = np.array(pil_image.convert('RGB'))
        # RGB â†’ BGR ë³€í™˜
        image_array = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)

        return self.detect(image_array)

    def is_ready(self) -> bool:
        """ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•œ ìƒíƒœì¸ì§€ í™•ì¸"""
        return self.session is not None and self.model_path.exists()